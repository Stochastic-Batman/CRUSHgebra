{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd01a4fc25dc3520",
   "metadata": {},
   "source": [
    "# **CRUSHgebra**\n",
    "\n",
    "The goal of this project is to design and train a single neural network that can perform two different tasks simultaneously (Multi-Task Learning).\n",
    "1. Task 1 is regression, aiming to predict the student's final grade, `G3` (a number from 0 to 20).\n",
    "2. Task 2 is classification, aiming to determine whether the student is in a `romantic` relationship or not.\n",
    "   \n",
    "This notebook fully covers all the code and experiments included in this repository through Python scripts. The interpreter used to run the code snippets in this notebook was 3.14; it was the same interpreter used for the entire project. After ensuring that you are using Python 3.14, install all the necessary libraries for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812f22341ae85723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:52.101280Z",
     "start_time": "2025-11-04T09:24:49.139198Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (2.3.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: torch in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: ucimlrepo in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from ucimlrepo) (2025.10.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U numpy pandas scikit-learn torch ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2e82bc-19f7-4cef-8e74-eaa7cb2d0529",
   "metadata": {},
   "source": [
    "Here I will list all the imports used throughout the notebook (and project) so that I will not need to need to run any functional code snippet twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8720f73-a904-49a3-baf4-ab664ee0425c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:55.159247Z",
     "start_time": "2025-11-04T09:24:52.137583Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, f1_score, classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5df1b-a8f6-4b24-9afb-b34a92f83cfc",
   "metadata": {},
   "source": [
    "Now let's start by using UC Irvine's Python API to retrieve the \"Student Performance\" dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22131530-8fcd-45c5-8989-a3a70b8a30fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.502674Z",
     "start_time": "2025-11-04T09:24:55.171033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_performance = fetch_ucirepo(name=\"Student Performance\")\n",
    "student_performance.metadata.additional_info.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7e7775f33ead7",
   "metadata": {},
   "source": [
    "### Attributes of the dataset:\n",
    "1. school: student's school (binary: \"GP\" - Gabriel Pereira or \"MS\" - Mousinho da Silveira)\n",
    "2. sex: student's sex (binary: \"F\" - female or \"M\" - male)\n",
    "3. age: student's age (numeric: from 15 to 22)\n",
    "4. address: student's home address type (binary: \"U\" - urban or \"R\" - rural)\n",
    "5. famsize: family size (binary: \"LE3\" - less or equal to 3 or \"GT3\" - greater than 3)\n",
    "6. Pstatus: parent's cohabitation status (binary: \"T\" - living together or \"A\" - apart)\n",
    "7. Medu: mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education)\n",
    "8. Fedu: father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education)\n",
    "9. Mjob: mother's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "10. Fjob: father's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "11. reason: reason to choose this school (nominal: close to \"home\", school \"reputation\", \"course\" preference or \"other\")\n",
    "12. guardian: student's guardian (nominal: \"mother\", \"father\" or \"other\")\n",
    "13. traveltime: home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "14. studytime: weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "15. failures: number of past class failures (numeric: n if $1 \\leq n <3$, else 4)\n",
    "16. schoolsup: extra educational support (binary: yes or no)\n",
    "17. famsup: family educational support (binary: yes or no)\n",
    "18. paid: extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "19. activities: extra-curricular activities (binary: yes or no)\n",
    "20. nursery: attended nursery school (binary: yes or no)\n",
    "21. higher: wants to take higher education (binary: yes or no)\n",
    "22. internet: Internet access at home (binary: yes or no)\n",
    "23. ***romantic***: with a romantic relationship (binary: yes or no) [TARGET]\n",
    "24. famrel: quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "25. freetime: free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "26. goout: going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "27. Dalc: workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "28. Walc: weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "29. health: current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "30. absences: number of school absences (numeric: from 0 to 93)\n",
    "\n",
    "These grades are related with the course subject, Math or Portuguese:\n",
    "\n",
    "31. G1: first period grade (numeric: from 0 to 20)\n",
    "31. G2: second period grade (numeric: from 0 to 20)\n",
    "32. ***G3***: final grade (numeric: from 0 to 20) [TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d0488-c913-421c-a309-ef491822abcc",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing (`preprocessing.py`)\n",
    "\n",
    "Just like the majority of machine learning models, neural network performance heavily relies on the quality of the data used to train and evaluate it. Additionally, neural networks only accept numeric data as input, so categorical data needs to be transformed into numerical format as well.\n",
    "\n",
    "Usually, one would check for missing values, but since the UCI website states that **there are no missing values** in the dataset, we can skip this step.\n",
    "\n",
    "In this order, we will:\n",
    "1. Separate target variables\n",
    "2. Perform a train/test split\n",
    "3. Encode categorical variables into numerical ones\n",
    "4. Normalize/standardize numerical variables\n",
    "\n",
    "First, we separate the target variables from the dataset. Now, grades (`G1`, `G2`, `G3`) are in `student_performance.data.targets`, while the rest are under `student_performance.data.features`.\n",
    "\n",
    "From the [webpage for the dataset](https://archive.ics.uci.edu/dataset/320/student+performance), we read:\n",
    "> Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).\n",
    "\n",
    "So we will ignore `G1` and `G2` altogether, separating `romantic`, `G3`, and all the remaining features of `student_performance.data.features`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2146246e-35cd-486f-babf-fac4f65bd321",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.547413Z",
     "start_time": "2025-11-04T09:24:58.539912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "romantic\n",
       "no     410\n",
       "yes    239\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G3 = student_performance.data.targets[\"G3\"]\n",
    "romantic = student_performance.data.features[\"romantic\"]\n",
    "X = student_performance.data.features.drop(columns=[\"romantic\"])\n",
    "y = pd.DataFrame({\"G3\": G3, \"romantic\": romantic})\n",
    "og_columns = [col for col in X.columns]\n",
    "\n",
    "# is \"romantic\" disbalanced? yes, it is\n",
    "y[\"romantic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c9889-0893-4e42-8215-679297e43b5f",
   "metadata": {},
   "source": [
    "Now, we perform a train/test split. `random_state` for reproducibility (95 for Lightning McQueen); `stratify` to ensure balanced distribution for `romantic`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc18285-6e2f-4595-b1cf-2fc8303c0f9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.605350Z",
     "start_time": "2025-11-04T09:24:58.558792Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=95, stratify=y[\"romantic\"])\n",
    "\n",
    "G3_train, G3_test = y_train[\"G3\"], y_test[\"G3\"]\n",
    "romantic_train, romantic_test = y_train[\"romantic\"], y_test[\"romantic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0230107-7a06-4dfe-bdc0-52d485306f6f",
   "metadata": {},
   "source": [
    "We will now check which of our variables are categorical and which are numerical, and then start by converting the categorical variables into numerical format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de7daac-9c47-44be-a49d-eaf52df5d9c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.625998Z",
     "start_time": "2025-11-04T09:24:58.620141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school: object\n",
      "sex: object\n",
      "age: int64\n",
      "address: object\n",
      "famsize: object\n",
      "Pstatus: object\n",
      "Medu: int64\n",
      "Fedu: int64\n",
      "Mjob: object\n",
      "Fjob: object\n",
      "reason: object\n",
      "guardian: object\n",
      "traveltime: int64\n",
      "studytime: int64\n",
      "failures: int64\n",
      "schoolsup: object\n",
      "famsup: object\n",
      "paid: object\n",
      "activities: object\n",
      "nursery: object\n",
      "higher: object\n",
      "internet: object\n",
      "famrel: int64\n",
      "freetime: int64\n",
      "goout: int64\n",
      "Dalc: int64\n",
      "Walc: int64\n",
      "health: int64\n",
      "absences: int64\n"
     ]
    }
   ],
   "source": [
    "for col in X_train.columns:\n",
    "    print(f\"{col}: {X_train[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b58ee23-62e6-439c-9b28-fa04f853f8c4",
   "metadata": {},
   "source": [
    "As we can see, for this particular dataset, the datatype for all of the categorical variables is `\"object\"`, so we can proceed with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd124907-1fab-47a5-98df-327ac6b91ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.652199Z",
     "start_time": "2025-11-04T09:24:58.646754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet']\n",
      "['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = []\n",
    "numerical_columns = []\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == \"object\":\n",
    "        categorical_columns.append(col)\n",
    "    else:\n",
    "        numerical_columns.append(col)\n",
    "\n",
    "print(categorical_columns)\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3958d-5e9b-4ea4-b4f7-d8458bf757f4",
   "metadata": {},
   "source": [
    "For both categorical and numerical variables, we fit the encoder, normalizer, or standardizer on `X_train`, and then apply the fitted method to `X_test` to prevent data leakage.\n",
    "\n",
    "As for the strategy of encoding categorical variables:\n",
    "- For binary categorical variables, binary encoding doesn't create artificial ordinal relationships. Each variable will simply map to 0 or 1.\n",
    "- For nominal variables (`Mjob`, `Fjob`, `reason`, `guardian`), one-hot encoding creates binary columns for each category, preventing the model from assuming false ordinal relationships (e.g., \"teacher\" > \"health\"). This is not an overhead, as none of these variables take more than four possible values.\n",
    "- Ordinal categorical variables are numerical features for this dataset. We standardize all numerical columns. This is necessary because even though ordinal variables have meaningful ordering, they exist on different scales (some 0-4, others 1-5, and `absences` goes 0-93), which would cause the neural network to give disproportionate weight to larger-scale features during gradient descent. Standardization puts all features on the same scale ($\\mu=0, \\sigma=1$) so the network can learn their relative importance based on predictive power, not magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c70c0bd3-3c4c-44ed-b13a-e03f7c501276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.713031Z",
     "start_time": "2025-11-04T09:24:58.672044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Binary categorical variables (encode as 0/1)\n",
    "binary_columns = [\"school\", \"sex\", \"address\", \"famsize\", \"Pstatus\", \"schoolsup\", \"famsup\", \"paid\", \"activities\", \"nursery\", \"higher\", \"internet\"]\n",
    "# Nominal categorical variables (one-hot encode)\n",
    "nominal_columns = [\"Mjob\", \"Fjob\", \"reason\", \"guardian\"]\n",
    "\n",
    "# Create the preprocessor\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"binary\", OrdinalEncoder(), binary_columns),\n",
    "        (\"nominal\", OneHotEncoder(drop=\"first\", sparse_output=False, handle_unknown=\"ignore\"), nominal_columns),\n",
    "        (\"numerical\", StandardScaler(), numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit on training data ONLY\n",
    "column_transformer.fit(X_train)\n",
    "\n",
    "# Transform both training and test sets\n",
    "X_train_encoded = column_transformer.transform(X_train)\n",
    "X_test_encoded = column_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e0ba96-8bfc-498b-89f0-9c6f04fe781b",
   "metadata": {},
   "source": [
    "Converting back to DataFrame for easier inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d897171-f17d-467a-abc4-5be3ccc9093f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.729020Z",
     "start_time": "2025-11-04T09:24:58.723970Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = (\n",
    "    binary_columns + \n",
    "    column_transformer.named_transformers_[\"nominal\"].get_feature_names_out(nominal_columns).tolist() +\n",
    "    numerical_columns\n",
    ")\n",
    "\n",
    "X_train_encoded = pd.DataFrame(X_train_encoded, columns=feature_names, index=X_train.index)\n",
    "X_test_encoded = pd.DataFrame(X_test_encoded, columns=feature_names, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e9d25-712c-4cae-b78c-0184de438c9b",
   "metadata": {},
   "source": [
    "Let's create a custom PyTorch dataset (`CrushSet.py`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "127fc0dc-d5bf-4c07-8ff7-49829273500a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.745432Z",
     "start_time": "2025-11-04T09:24:58.739921Z"
    }
   },
   "outputs": [],
   "source": [
    "class CrushSet(Dataset):\n",
    "    def __init__(self, X: pd.DataFrame, y: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Create a dataset for heartbroken nerds. (Not for me I swear, I have the most beautiful and loving girlfriend in the history of the world)\n",
    "\n",
    "        Args:\n",
    "            X: (n_samples, n_features) -> preprocessed features\n",
    "            y: (n_samples, 2) -> targets DataFrame containing both 'G3' and 'romantic' columns\n",
    "        \"\"\"\n",
    "        self.X = torch.FloatTensor(X.values)\n",
    "        self.y_G3 = torch.FloatTensor(y[\"G3\"].values)\n",
    "        self.y_romantic = torch.LongTensor((y[\"romantic\"] == \"yes\").astype(int).values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns three items: (x_data, y_G3_data, y_romantic_data)\n",
    "\n",
    "        Returns:\n",
    "            x_data: feature vector, shape (n_features,)\n",
    "            y_G3_data: grade target (scalar)\n",
    "            y_romantic_data: romantic status target (0 or 1)\n",
    "        \"\"\"\n",
    "        return self.X[idx], self.y_G3[idx], self.y_romantic[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a187b3d-8450-43f7-ad70-41523ab05d0a",
   "metadata": {},
   "source": [
    "Completing train/test/validation split and creating DataLoaders (this snippet of code is implemented in `train.py`, which we'll cover later, but here we can avoid saving the split results and reloading them.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c90bbf87-7525-44cf-a049-54c78ca1095e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.764777Z",
     "start_time": "2025-11-04T09:24:58.755356Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split train into train and validation sets (80/20 split of training data)\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_encoded, y_train, test_size=0.2, random_state=95, stratify=y_train[\"romantic\"])\n",
    "\n",
    "# Create Dataset instances\n",
    "train_dataset = CrushSet(X_train_final, y_train_final)\n",
    "test_dataset = CrushSet(X_test_encoded, y_test)\n",
    "val_dataset = CrushSet(X_val, y_val)\n",
    "\n",
    "# Create DataLoaders\n",
    "BS = 32  # yeah, let's go with the default batch size\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab7865f-0fba-4df2-8245-cba9be0a1a79",
   "metadata": {},
   "source": [
    "## Part 2: Building the Multi-Head Model (`TwoRabbitsHunter.py`)\n",
    "\n",
    "In this task, we will create a single neural network with a shared feature-extractor(\"body\") and two task-specific output modules(\"heads\").\n",
    "\n",
    "- Shared body: a feedforward feature extractor that transforms input features into a compact shared representation using repeated blocks of linear projection, nonlinearity, normalization, and regularization. This body is responsible for learning the common student-profile features useful to both tasks.\n",
    "\n",
    "- First Head: Grade prediction (regression) - a small feedforward module that takes the shared representation and produces one continuous scalar - the predicted grade.\n",
    "\n",
    "- Second Head: Romantic status (classification) - a small feedforward module that takes the same shared representation and produces two output scores (logits) corresponding to the \"yes\"/\"no\" classes.\n",
    "\n",
    "- Data flow: inputs go into the shared body; its output is forwarded in parallel to both heads; the model returns both the scalar regression output and the two-class logits.\n",
    "\n",
    "I will name the class `TwoRabbitsHunter`, after a Georgian saying that roughly translates to: \n",
    ">A hunter who chases two rabbits will catch neither."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a47b96e33a80e0c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.780575Z",
     "start_time": "2025-11-04T09:24:58.774134Z"
    }
   },
   "outputs": [],
   "source": [
    "class TwoRabbitsHunter(nn.Module):\n",
    "    HEAD_SIZE = 6\n",
    "    \n",
    "    def __init__(self, input_size=38, hidden_size=16, shared_output_size=8, dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        Class to simultaneously predict G3 (regression) and romantic (classification)\n",
    "\n",
    "        Args:\n",
    "            input_size: Number of input features (X_train_encoded.shape[1] == 38)\n",
    "            hidden_size: Size of hidden layers in shared body\n",
    "            shared_output_size: Size of final shared representation\n",
    "            dropout_rate: Dropout probability for regularization\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # shared body\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_size, shared_output_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm1d(shared_output_size)  # this is where the shared body ends\n",
    "\n",
    "        # regression head\n",
    "        self.G3_fc1 = nn.Linear(shared_output_size, self.HEAD_SIZE)\n",
    "        self.G3_relu = nn.ReLU()\n",
    "        self.G3_bn = nn.BatchNorm1d(self.HEAD_SIZE)\n",
    "        self.G3_dropout = nn.Dropout(dropout_rate)\n",
    "        self.G3_fc2 = nn.Linear(self.HEAD_SIZE, 1)  # G3\n",
    "\n",
    "        # classification head\n",
    "        self.romantic_fc1 = nn.Linear(shared_output_size, self.HEAD_SIZE)\n",
    "        self.romantic_relu = nn.ReLU()\n",
    "        self.romantic_bn = nn.BatchNorm1d(self.HEAD_SIZE)\n",
    "        self.romantic_dropout = nn.Dropout(dropout_rate)\n",
    "        self.romantic_fc2 = nn.Linear(self.HEAD_SIZE, 2)  # romantic logits (\"yes\"/\"no\")\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.bn1(self.relu1(self.fc1(x))))\n",
    "        x = self.bn2(self.relu2(self.fc2(x)))\n",
    "\n",
    "        G3_pred = self.G3_fc2(self.G3_dropout(self.G3_bn(self.G3_relu(self.G3_fc1(x)))))\n",
    "        romantic_logits = self.romantic_fc2(self.romantic_dropout(self.romantic_bn(self.romantic_relu(self.romantic_fc1(x)))))\n",
    "\n",
    "        return G3_pred, romantic_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7188d3e-6c72-494f-9acc-6c4b86827de2",
   "metadata": {},
   "source": [
    "As `X_train_encoded.shape = (519, 38)`, a compact two-layer shared body ($38 \\to 16 \\to $ `HEAD_SIZE`) prevents overfitting while maintaining sufficient representational capacity. The parameter count of $\\approx 1,500$ aligns better with the dataset size compared to deeper alternatives. Each head uses a single hidden layer of `HEAD_SIZE` neurons before outputting predictions. A single dropout layer after the first shared layer provides regularization at the point of highest dimensionality where overfitting risk is greatest, while the second layer's batch normalization alone sufficiently regularizes the smaller `HEAD_SIZE`-dimensional representation that feeds into both specialized heads. Dropout rate of $0.2$ is a classic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b7f12f-9236-4e52-b6c8-11a554ff074e",
   "metadata": {},
   "source": [
    "## Part 3: The Custom Training Loop (`train.py`)\n",
    "\n",
    "We will implement a training and validation procedure tailored for a multi-task model with two separate objectives.\n",
    "\n",
    "Training loop:\n",
    "- Define two appropriate loss functions: one for the regression task and one for the classification task.\n",
    "- For each training batch, run a forward pass and obtain two outputs from the model: the regression prediction and the classification logits.\n",
    "- Compute each task's loss separately using the corresponding predictions and targets, taking care that targets and predictions have the correct shapes and types for each loss.\n",
    "- Combine the two task losses into a single scalar `total_loss` (for example by summing them, or using weighted sum if we choose to weight tasks differently).\n",
    "- Backpropagate once on `total_loss` so gradients flow through both heads and the shared body together.\n",
    "- Update model parameters based on the aggregated gradients.\n",
    "\n",
    "Validation loop:\n",
    "- Run the model on validation data in evaluation mode and obtain both outputs per batch.\n",
    "- Compute each task's validation loss separately, accumulate them across the validation set, and report both validation losses (and optionally their combined value).\n",
    "- Use these validation losses to monitor training progress and for early stopping or hyperparameter decisions.\n",
    "\n",
    "But before the loops, let's configure logger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86e7c876-99b9-4605-94fe-d41a60d16768",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.794218Z",
     "start_time": "2025-11-04T09:24:58.790383Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d7627-6839-47f1-92fa-2e8e6f4913a2",
   "metadata": {},
   "source": [
    "Some definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0123029e-4408-4a38-8117-51be57f6405a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:25:00.148226Z",
     "start_time": "2025-11-04T09:24:58.802805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute weights for class imbalance\n",
    "romantic_labels = [int(y) for _, _, y in train_dataset]\n",
    "class_counts = Counter(romantic_labels)\n",
    "total = sum(class_counts.values())\n",
    "weights = [total / class_counts[i] for i in range(2)]  # [weight for 0, weight for 1]\n",
    "sample_weights = [weights[y] for y in romantic_labels]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False)\n",
    "\n",
    "# Initialize model, model parameters, loss functions, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Unfortunately, I have never had a CUDA-supported personal computer, except for the time I ran my FIRST EVER DISTRIBUTED PROGRAM ON EUROPE'S CURRENT LARGEST SUPERCOMPUTER â€” JUPYTER (during my summer 2025 internship).\n",
    "model = TwoRabbitsHunter(input_size=X_train_encoded.shape[1]).to(device)\n",
    "\n",
    "regression_loss_fn = nn.MSELoss()  # For grade prediction (G3)\n",
    "class_weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
    "classification_loss_fn = nn.CrossEntropyLoss(weight=class_weights)  # For romantic status\n",
    "\n",
    "learning_rate = 0.0005\n",
    "weight_decay = 1e-4\n",
    "alpha = 0.7  # Weight for grade loss (1-alpha for romantic loss)\n",
    "epochs = 500\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608f0a59-1530-425a-bd9d-1b0d882bbbad",
   "metadata": {},
   "source": [
    "Now, let's start out training loop!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c32be42a-f0be-42ce-b8ce-ceb3cfc7fe3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:25:00.180939Z",
     "start_time": "2025-11-04T09:25:00.170730Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 14:28:38,104 - INFO - Starting training...\n",
      "2025-11-05 14:28:38,105 - INFO - Using device: cpu\n",
      "2025-11-05 14:28:38,105 - INFO - Alpha (G3 weight): 0.7\n",
      "2025-11-05 14:28:38,106 - INFO - Optimizer: AdamW\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting training...\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "logger.info(f\"Alpha (G3 weight): {alpha}\")\n",
    "logger.info(f\"Optimizer: {optimizer.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3d8812f-bbd7-41ba-a5fc-caec9017a67b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:25:38.175667Z",
     "start_time": "2025-11-04T09:25:00.206810Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 14:28:38,706 - INFO - Epoch [10/500]\n",
      "2025-11-05 14:28:38,707 - INFO -   Train -> Total: 99.972, G3: 142.518, Romantic: 0.698\n",
      "2025-11-05 14:28:38,707 - INFO -   Val -> Total: 99.531, G3: 141.881, Romantic: 0.715\n",
      "2025-11-05 14:28:39,260 - INFO - Epoch [20/500]\n",
      "2025-11-05 14:28:39,261 - INFO -   Train -> Total: 104.068, G3: 148.377, Romantic: 0.682\n",
      "2025-11-05 14:28:39,262 - INFO -   Val -> Total: 96.266, G3: 137.217, Romantic: 0.713\n",
      "2025-11-05 14:28:39,830 - INFO - Epoch [30/500]\n",
      "2025-11-05 14:28:39,831 - INFO -   Train -> Total: 94.867, G3: 135.233, Romantic: 0.680\n",
      "2025-11-05 14:28:39,831 - INFO -   Val -> Total: 89.565, G3: 127.643, Romantic: 0.717\n",
      "2025-11-05 14:28:40,403 - INFO - Epoch [40/500]\n",
      "2025-11-05 14:28:40,403 - INFO -   Train -> Total: 88.930, G3: 126.755, Romantic: 0.672\n",
      "2025-11-05 14:28:40,404 - INFO -   Val -> Total: 82.897, G3: 118.116, Romantic: 0.719\n",
      "2025-11-05 14:28:40,974 - INFO - Epoch [50/500]\n",
      "2025-11-05 14:28:40,974 - INFO -   Train -> Total: 81.325, G3: 115.895, Romantic: 0.662\n",
      "2025-11-05 14:28:40,975 - INFO -   Val -> Total: 75.573, G3: 107.653, Romantic: 0.721\n",
      "2025-11-05 14:28:41,554 - INFO - Epoch [60/500]\n",
      "2025-11-05 14:28:41,555 - INFO -   Train -> Total: 75.352, G3: 107.365, Romantic: 0.657\n",
      "2025-11-05 14:28:41,555 - INFO -   Val -> Total: 66.761, G3: 95.063, Romantic: 0.723\n",
      "2025-11-05 14:28:42,107 - INFO - Epoch [70/500]\n",
      "2025-11-05 14:28:42,108 - INFO -   Train -> Total: 67.243, G3: 95.778, Romantic: 0.660\n",
      "2025-11-05 14:28:42,108 - INFO -   Val -> Total: 57.361, G3: 81.635, Romantic: 0.723\n",
      "2025-11-05 14:28:42,672 - INFO - Epoch [80/500]\n",
      "2025-11-05 14:28:42,673 - INFO -   Train -> Total: 56.933, G3: 81.057, Romantic: 0.644\n",
      "2025-11-05 14:28:42,673 - INFO -   Val -> Total: 50.267, G3: 71.497, Romantic: 0.730\n",
      "2025-11-05 14:28:43,246 - INFO - Epoch [90/500]\n",
      "2025-11-05 14:28:43,246 - INFO -   Train -> Total: 47.250, G3: 67.215, Romantic: 0.666\n",
      "2025-11-05 14:28:43,247 - INFO -   Val -> Total: 40.732, G3: 57.874, Romantic: 0.732\n",
      "2025-11-05 14:28:43,796 - INFO - Epoch [100/500]\n",
      "2025-11-05 14:28:43,797 - INFO -   Train -> Total: 39.426, G3: 56.038, Romantic: 0.665\n",
      "2025-11-05 14:28:43,797 - INFO -   Val -> Total: 34.012, G3: 48.275, Romantic: 0.731\n",
      "2025-11-05 14:28:44,367 - INFO - Epoch [110/500]\n",
      "2025-11-05 14:28:44,368 - INFO -   Train -> Total: 32.954, G3: 46.790, Romantic: 0.672\n",
      "2025-11-05 14:28:44,368 - INFO -   Val -> Total: 27.513, G3: 38.991, Romantic: 0.729\n",
      "2025-11-05 14:28:44,953 - INFO - Epoch [120/500]\n",
      "2025-11-05 14:28:44,954 - INFO -   Train -> Total: 28.332, G3: 40.194, Romantic: 0.656\n",
      "2025-11-05 14:28:44,955 - INFO -   Val -> Total: 21.075, G3: 29.796, Romantic: 0.725\n",
      "2025-11-05 14:28:45,512 - INFO - Epoch [130/500]\n",
      "2025-11-05 14:28:45,513 - INFO -   Train -> Total: 21.294, G3: 30.141, Romantic: 0.651\n",
      "2025-11-05 14:28:45,513 - INFO -   Val -> Total: 16.950, G3: 23.903, Romantic: 0.725\n",
      "2025-11-05 14:28:46,090 - INFO - Epoch [140/500]\n",
      "2025-11-05 14:28:46,091 - INFO -   Train -> Total: 18.842, G3: 26.638, Romantic: 0.653\n",
      "2025-11-05 14:28:46,092 - INFO -   Val -> Total: 13.842, G3: 19.463, Romantic: 0.727\n",
      "2025-11-05 14:28:46,695 - INFO - Epoch [150/500]\n",
      "2025-11-05 14:28:46,696 - INFO -   Train -> Total: 16.790, G3: 23.708, Romantic: 0.647\n",
      "2025-11-05 14:28:46,696 - INFO -   Val -> Total: 11.533, G3: 16.163, Romantic: 0.731\n",
      "2025-11-05 14:28:47,288 - INFO - Epoch [160/500]\n",
      "2025-11-05 14:28:47,289 - INFO -   Train -> Total: 13.433, G3: 18.922, Romantic: 0.626\n",
      "2025-11-05 14:28:47,289 - INFO -   Val -> Total: 8.845, G3: 12.323, Romantic: 0.730\n",
      "2025-11-05 14:28:47,911 - INFO - Epoch [170/500]\n",
      "2025-11-05 14:28:47,912 - INFO -   Train -> Total: 15.130, G3: 21.329, Romantic: 0.667\n",
      "2025-11-05 14:28:47,912 - INFO -   Val -> Total: 7.766, G3: 10.781, Romantic: 0.730\n",
      "2025-11-05 14:28:48,534 - INFO - Epoch [180/500]\n",
      "2025-11-05 14:28:48,535 - INFO -   Train -> Total: 9.861, G3: 13.802, Romantic: 0.665\n",
      "2025-11-05 14:28:48,535 - INFO -   Val -> Total: 6.783, G3: 9.379, Romantic: 0.725\n",
      "2025-11-05 14:28:49,147 - INFO - Epoch [190/500]\n",
      "2025-11-05 14:28:49,149 - INFO -   Train -> Total: 12.064, G3: 16.956, Romantic: 0.649\n",
      "2025-11-05 14:28:49,149 - INFO -   Val -> Total: 6.264, G3: 8.638, Romantic: 0.725\n",
      "2025-11-05 14:28:49,736 - INFO - Epoch [200/500]\n",
      "2025-11-05 14:28:49,737 - INFO -   Train -> Total: 10.219, G3: 14.329, Romantic: 0.632\n",
      "2025-11-05 14:28:49,737 - INFO -   Val -> Total: 5.884, G3: 8.094, Romantic: 0.727\n",
      "2025-11-05 14:28:50,306 - INFO - Epoch [210/500]\n",
      "2025-11-05 14:28:50,307 - INFO -   Train -> Total: 10.378, G3: 14.550, Romantic: 0.644\n",
      "2025-11-05 14:28:50,307 - INFO -   Val -> Total: 5.778, G3: 7.943, Romantic: 0.727\n",
      "2025-11-05 14:28:50,900 - INFO - Epoch [220/500]\n",
      "2025-11-05 14:28:50,901 - INFO -   Train -> Total: 9.636, G3: 13.485, Romantic: 0.655\n",
      "2025-11-05 14:28:50,902 - INFO -   Val -> Total: 5.730, G3: 7.873, Romantic: 0.728\n",
      "2025-11-05 14:28:51,477 - INFO - Epoch [230/500]\n",
      "2025-11-05 14:28:51,477 - INFO -   Train -> Total: 9.853, G3: 13.792, Romantic: 0.661\n",
      "2025-11-05 14:28:51,478 - INFO -   Val -> Total: 5.763, G3: 7.922, Romantic: 0.726\n",
      "2025-11-05 14:28:52,041 - INFO - Epoch [240/500]\n",
      "2025-11-05 14:28:52,042 - INFO -   Train -> Total: 10.235, G3: 14.339, Romantic: 0.659\n",
      "2025-11-05 14:28:52,042 - INFO -   Val -> Total: 5.770, G3: 7.931, Romantic: 0.727\n",
      "2025-11-05 14:28:52,601 - INFO - Epoch [250/500]\n",
      "2025-11-05 14:28:52,602 - INFO -   Train -> Total: 10.728, G3: 15.043, Romantic: 0.660\n",
      "2025-11-05 14:28:52,603 - INFO -   Val -> Total: 5.775, G3: 7.939, Romantic: 0.725\n",
      "2025-11-05 14:28:53,175 - INFO - Epoch [260/500]\n",
      "2025-11-05 14:28:53,176 - INFO -   Train -> Total: 9.180, G3: 12.832, Romantic: 0.660\n",
      "2025-11-05 14:28:53,177 - INFO -   Val -> Total: 5.726, G3: 7.868, Romantic: 0.728\n",
      "2025-11-05 14:28:53,743 - INFO - Epoch [270/500]\n",
      "2025-11-05 14:28:53,744 - INFO -   Train -> Total: 9.645, G3: 13.499, Romantic: 0.654\n",
      "2025-11-05 14:28:53,744 - INFO -   Val -> Total: 5.619, G3: 7.716, Romantic: 0.726\n",
      "2025-11-05 14:28:54,300 - INFO - Epoch [280/500]\n",
      "2025-11-05 14:28:54,301 - INFO -   Train -> Total: 11.577, G3: 16.254, Romantic: 0.665\n",
      "2025-11-05 14:28:54,301 - INFO -   Val -> Total: 5.634, G3: 7.738, Romantic: 0.725\n",
      "2025-11-05 14:28:54,859 - INFO - Epoch [290/500]\n",
      "2025-11-05 14:28:54,860 - INFO -   Train -> Total: 9.091, G3: 12.707, Romantic: 0.654\n",
      "2025-11-05 14:28:54,860 - INFO -   Val -> Total: 5.765, G3: 7.923, Romantic: 0.731\n",
      "2025-11-05 14:28:55,407 - INFO - Epoch [300/500]\n",
      "2025-11-05 14:28:55,408 - INFO -   Train -> Total: 9.616, G3: 13.449, Romantic: 0.671\n",
      "2025-11-05 14:28:55,409 - INFO -   Val -> Total: 5.614, G3: 7.709, Romantic: 0.724\n",
      "2025-11-05 14:28:55,954 - INFO - Epoch [310/500]\n",
      "2025-11-05 14:28:55,954 - INFO -   Train -> Total: 9.930, G3: 13.899, Romantic: 0.671\n",
      "2025-11-05 14:28:55,955 - INFO -   Val -> Total: 5.713, G3: 7.851, Romantic: 0.725\n",
      "2025-11-05 14:28:56,498 - INFO - Epoch [320/500]\n",
      "2025-11-05 14:28:56,499 - INFO -   Train -> Total: 9.805, G3: 13.739, Romantic: 0.627\n",
      "2025-11-05 14:28:56,499 - INFO -   Val -> Total: 5.645, G3: 7.752, Romantic: 0.728\n",
      "2025-11-05 14:28:57,056 - INFO - Epoch [330/500]\n",
      "2025-11-05 14:28:57,057 - INFO -   Train -> Total: 9.908, G3: 13.880, Romantic: 0.640\n",
      "2025-11-05 14:28:57,057 - INFO -   Val -> Total: 5.427, G3: 7.440, Romantic: 0.730\n",
      "2025-11-05 14:28:57,634 - INFO - Epoch [340/500]\n",
      "2025-11-05 14:28:57,634 - INFO -   Train -> Total: 10.534, G3: 14.770, Romantic: 0.650\n",
      "2025-11-05 14:28:57,635 - INFO -   Val -> Total: 5.556, G3: 7.625, Romantic: 0.729\n",
      "2025-11-05 14:28:58,236 - INFO - Epoch [350/500]\n",
      "2025-11-05 14:28:58,237 - INFO -   Train -> Total: 10.313, G3: 14.465, Romantic: 0.627\n",
      "2025-11-05 14:28:58,237 - INFO -   Val -> Total: 5.519, G3: 7.572, Romantic: 0.730\n",
      "2025-11-05 14:28:58,823 - INFO - Epoch [360/500]\n",
      "2025-11-05 14:28:58,824 - INFO -   Train -> Total: 9.482, G3: 13.261, Romantic: 0.665\n",
      "2025-11-05 14:28:58,824 - INFO -   Val -> Total: 5.496, G3: 7.541, Romantic: 0.725\n",
      "2025-11-05 14:28:59,378 - INFO - Epoch [370/500]\n",
      "2025-11-05 14:28:59,379 - INFO -   Train -> Total: 9.410, G3: 13.151, Romantic: 0.680\n",
      "2025-11-05 14:28:59,379 - INFO -   Val -> Total: 5.288, G3: 7.242, Romantic: 0.730\n",
      "2025-11-05 14:28:59,969 - INFO - Epoch [380/500]\n",
      "2025-11-05 14:28:59,970 - INFO -   Train -> Total: 8.986, G3: 12.551, Romantic: 0.668\n",
      "2025-11-05 14:28:59,970 - INFO -   Val -> Total: 5.288, G3: 7.242, Romantic: 0.729\n",
      "2025-11-05 14:29:00,535 - INFO - Epoch [390/500]\n",
      "2025-11-05 14:29:00,536 - INFO -   Train -> Total: 8.625, G3: 12.056, Romantic: 0.618\n",
      "2025-11-05 14:29:00,536 - INFO -   Val -> Total: 5.317, G3: 7.283, Romantic: 0.728\n",
      "2025-11-05 14:29:01,109 - INFO - Epoch [400/500]\n",
      "2025-11-05 14:29:01,110 - INFO -   Train -> Total: 10.528, G3: 14.758, Romantic: 0.659\n",
      "2025-11-05 14:29:01,110 - INFO -   Val -> Total: 5.380, G3: 7.371, Romantic: 0.734\n",
      "2025-11-05 14:29:01,655 - INFO - Epoch [410/500]\n",
      "2025-11-05 14:29:01,656 - INFO -   Train -> Total: 9.560, G3: 13.382, Romantic: 0.642\n",
      "2025-11-05 14:29:01,656 - INFO -   Val -> Total: 5.585, G3: 7.664, Romantic: 0.735\n",
      "2025-11-05 14:29:02,218 - INFO - Epoch [420/500]\n",
      "2025-11-05 14:29:02,219 - INFO -   Train -> Total: 9.368, G3: 13.116, Romantic: 0.622\n",
      "2025-11-05 14:29:02,219 - INFO -   Val -> Total: 5.303, G3: 7.261, Romantic: 0.734\n",
      "2025-11-05 14:29:02,771 - INFO - Epoch [430/500]\n",
      "2025-11-05 14:29:02,772 - INFO -   Train -> Total: 9.605, G3: 13.444, Romantic: 0.647\n",
      "2025-11-05 14:29:02,772 - INFO -   Val -> Total: 5.615, G3: 7.707, Romantic: 0.732\n",
      "2025-11-05 14:29:03,328 - INFO - Epoch [440/500]\n",
      "2025-11-05 14:29:03,329 - INFO -   Train -> Total: 9.414, G3: 13.169, Romantic: 0.652\n",
      "2025-11-05 14:29:03,329 - INFO -   Val -> Total: 5.426, G3: 7.439, Romantic: 0.731\n",
      "2025-11-05 14:29:03,883 - INFO - Epoch [450/500]\n",
      "2025-11-05 14:29:03,884 - INFO -   Train -> Total: 8.431, G3: 11.763, Romantic: 0.657\n",
      "2025-11-05 14:29:03,884 - INFO -   Val -> Total: 5.483, G3: 7.518, Romantic: 0.734\n",
      "2025-11-05 14:29:04,441 - INFO - Epoch [460/500]\n",
      "2025-11-05 14:29:04,441 - INFO -   Train -> Total: 9.186, G3: 12.857, Romantic: 0.619\n",
      "2025-11-05 14:29:04,442 - INFO -   Val -> Total: 5.350, G3: 7.331, Romantic: 0.728\n",
      "2025-11-05 14:29:05,027 - INFO - Epoch [470/500]\n",
      "2025-11-05 14:29:05,028 - INFO -   Train -> Total: 9.750, G3: 13.646, Romantic: 0.658\n",
      "2025-11-05 14:29:05,028 - INFO -   Val -> Total: 5.578, G3: 7.656, Romantic: 0.729\n",
      "2025-11-05 14:29:05,594 - INFO - Epoch [480/500]\n",
      "2025-11-05 14:29:05,595 - INFO -   Train -> Total: 10.052, G3: 14.089, Romantic: 0.634\n",
      "2025-11-05 14:29:05,596 - INFO -   Val -> Total: 5.322, G3: 7.292, Romantic: 0.726\n",
      "2025-11-05 14:29:06,149 - INFO - Epoch [490/500]\n",
      "2025-11-05 14:29:06,150 - INFO -   Train -> Total: 8.513, G3: 11.886, Romantic: 0.643\n",
      "2025-11-05 14:29:06,150 - INFO -   Val -> Total: 5.364, G3: 7.350, Romantic: 0.729\n",
      "2025-11-05 14:29:06,711 - INFO - Epoch [500/500]\n",
      "2025-11-05 14:29:06,712 - INFO -   Train -> Total: 7.823, G3: 10.889, Romantic: 0.669\n",
      "2025-11-05 14:29:06,712 - INFO -   Val -> Total: 5.387, G3: 7.385, Romantic: 0.725\n",
      "2025-11-05 14:29:06,713 - INFO - Training completed!\n",
      "2025-11-05 14:29:06,717 - INFO - Model saved to 'tmp/TwoRabbitsHunter.pth'\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_G3_loss = 0.0\n",
    "    train_romantic_loss = 0.0\n",
    "    train_total_loss = 0.0\n",
    "    train_batches = 0.0\n",
    "\n",
    "    for batch_X, batch_G3, batch_romantic in train_loader:\n",
    "        batch_X = batch_X.to(device)  # hoping we get CUDA someday....\n",
    "        batch_G3 = batch_G3.to(device)\n",
    "        batch_romantic = batch_romantic.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        G3_pred, romantic_logits = model(batch_X)\n",
    "\n",
    "        G3_loss = regression_loss_fn(G3_pred.squeeze(), batch_G3)\n",
    "        romantic_loss = classification_loss_fn(romantic_logits, batch_romantic)\n",
    "        total_loss = alpha * G3_loss + (1 - alpha) * romantic_loss  # ahh, the good old convex combination\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_G3_loss += G3_loss.item()\n",
    "        train_romantic_loss += romantic_loss.item()\n",
    "        train_total_loss += total_loss.item()\n",
    "        train_batches += 1\n",
    "\n",
    "    avg_train_G3 = train_G3_loss / train_batches\n",
    "    avg_train_romantic = train_romantic_loss / train_batches\n",
    "    avg_train_total = train_total_loss / train_batches\n",
    "\n",
    "    # validation phase\n",
    "    model.eval()\n",
    "    val_G3_loss = 0.0\n",
    "    val_romantic_loss = 0.0\n",
    "    val_total_loss = 0.0\n",
    "    val_batches = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_G3, batch_romantic in val_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_G3 = batch_G3.to(device)\n",
    "            batch_romantic = batch_romantic.to(device)\n",
    "\n",
    "            G3_pred, romantic_logits = model(batch_X)\n",
    "\n",
    "            G3_loss = regression_loss_fn(G3_pred.squeeze(), batch_G3)\n",
    "            romantic_loss = classification_loss_fn(romantic_logits, batch_romantic)\n",
    "            total_loss = alpha * G3_loss + (1 - alpha) * romantic_loss\n",
    "\n",
    "            val_G3_loss += G3_loss.item()\n",
    "            val_romantic_loss += romantic_loss.item()\n",
    "            val_total_loss += total_loss.item()\n",
    "            val_batches += 1\n",
    "\n",
    "\n",
    "    avg_val_total = val_total_loss / val_batches\n",
    "    avg_val_G3 = val_G3_loss / val_batches\n",
    "    avg_val_romantic = val_romantic_loss / val_batches\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        logger.info(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "        logger.info(f\"  Train -> Total: {avg_train_total:.3f}, G3: {avg_train_G3:.3f}, Romantic: {avg_train_romantic:.3f}\")\n",
    "        logger.info(f\"  Val -> Total: {avg_val_total:.3f}, G3: {avg_val_G3:.3f}, Romantic: {avg_val_romantic:.3f}\")\n",
    "\n",
    "\n",
    "logger.info(\"Training completed!\")\n",
    "os.makedirs(\"tmp\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"tmp/TwoRabbitsHunter.pth\")  # Saving the model in PyTorch format\n",
    "logger.info(\"Model saved to 'tmp/TwoRabbitsHunter.pth'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab7868f-04f2-4d62-bed3-8f8e6c02f165",
   "metadata": {},
   "source": [
    "And the final evaluation on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bf50d5f-62b7-4dc6-bca8-8fa4c5cb38eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:25:38.231018Z",
     "start_time": "2025-11-04T09:25:38.212699Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 14:29:06,729 - INFO - Final Test Results:\n",
      "2025-11-05 14:29:06,730 - INFO - Test -> Total: 6.059, G3: 8.337, Romantic: 0.743\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_G3_loss = 0.0\n",
    "test_romantic_loss = 0.0\n",
    "test_total_loss = 0.0\n",
    "test_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_G3, batch_romantic in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_G3 = batch_G3.to(device)\n",
    "        batch_romantic = batch_romantic.to(device)\n",
    "\n",
    "        G3_pred, romantic_logits = model(batch_X)\n",
    "\n",
    "        G3_loss = regression_loss_fn(G3_pred.squeeze(), batch_G3)\n",
    "        romantic_loss = classification_loss_fn(romantic_logits, batch_romantic)\n",
    "        total_loss = alpha * G3_loss + (1 - alpha) * romantic_loss\n",
    "\n",
    "        test_total_loss += total_loss.item()\n",
    "        test_G3_loss += G3_loss.item()\n",
    "        test_romantic_loss += romantic_loss.item()\n",
    "        test_batches += 1\n",
    "\n",
    "logger.info(f\"Final Test Results:\")\n",
    "logger.info(f'Test -> Total: {test_total_loss / test_batches:.3f}, G3: {test_G3_loss / test_batches:.3f}, Romantic: {test_romantic_loss / test_batches:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3486a9c-599e-4af9-83d3-d0775a0659cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:25:38.250400Z",
     "start_time": "2025-11-04T09:25:38.247607Z"
    }
   },
   "source": [
    "## Part 4: Evaluation & Analysis\n",
    "\n",
    "A single \"accuracy\" score is meaningless. We must evaluate each task's performance on test set. \n",
    "\n",
    "- For `G3` prediction:\n",
    "  - We report the Mean Absolute Error (MAE). This tells us, \"On average, how many grade points was our model's prediction off by?\". We use MAE because its scale is more intuitive than MSE's (humans tend to comprehend the average difference in grade points better than the squared metric of MSE).\n",
    "  \n",
    "- For `romantic` prediction:\n",
    "  - We report accuracy.\n",
    "  - Additionally, we report the F1-Score (for the \"yes\" class). This is crucial, as the classes are imbalanced and it balances precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c89375c4-fb86-4d72-8fd6-b807b0c45232",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_G3_preds = []\n",
    "all_G3_true = []\n",
    "all_romantic_preds = []\n",
    "all_romantic_true = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb1bf8b-e79d-4336-bc4d-c326b6c25eda",
   "metadata": {},
   "source": [
    "Here is the test loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70368a89-c945-44b5-b9d4-160ca1026061",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_X, batch_G3, batch_romantic in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_G3 = batch_G3.to(device)\n",
    "        batch_romantic = batch_romantic.to(device)\n",
    "\n",
    "        G3_pred, romantic_logits = model(batch_X)\n",
    "\n",
    "        all_G3_preds.extend(G3_pred.squeeze().cpu().numpy())\n",
    "        all_G3_true.extend(batch_G3.cpu().numpy())\n",
    "\n",
    "        romantic_pred_classes = torch.argmax(romantic_logits, dim=1)\n",
    "        all_romantic_preds.extend(romantic_pred_classes.cpu().numpy())\n",
    "        all_romantic_true.extend(batch_romantic.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c7a51-3449-4cd6-8db7-24f4ba9d1a0c",
   "metadata": {},
   "source": [
    "Converting to numpy and calculating the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d63b5e9-8c7f-4b1e-849b-a9e1bc32939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_G3_preds = np.array(all_G3_preds)\n",
    "all_G3_true = np.array(all_G3_true)\n",
    "all_romantic_preds = np.array(all_romantic_preds)\n",
    "all_romantic_true = np.array(all_romantic_true)\n",
    "\n",
    "mae_G3 = mean_absolute_error(all_G3_true, all_G3_preds)\n",
    "accuracy_romantic = accuracy_score(all_romantic_true, all_romantic_preds)\n",
    "f1_romantic_yes = f1_score(all_romantic_true, all_romantic_preds, pos_label=1)\n",
    "unique, counts = np.unique(all_romantic_true, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f09fc91-51b6-4960-b9b6-9d9d14f1ee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 1 1 1 0 1\n",
      " 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 1 0 0\n",
      " 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 1 1 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(all_romantic_preds)\n",
    "print(all_romantic_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adca1e31-0341-4e9f-82b3-f5460dcecf33",
   "metadata": {},
   "source": [
    "and logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31a61fff-95fe-4ef8-86f1-5fc2a0cfa903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 14:29:06,764 - INFO - ==================================================\n",
      "2025-11-05 14:29:06,765 - INFO - G3 prediction (regression)\n",
      "2025-11-05 14:29:06,765 - INFO - ==================================================\n",
      "2025-11-05 14:29:06,766 - INFO - Mean Absolute Error (MAE): 2.065 grade points\n",
      "2025-11-05 14:29:06,767 - INFO - Interpretation: On average, predictions are off by 2.065 points (out of 20)\n",
      "2025-11-05 14:29:06,767 - INFO - \n",
      "==================================================\n",
      "2025-11-05 14:29:06,768 - INFO - Romantic prediction (classification) - many students wish they could predict this\n",
      "2025-11-05 14:29:06,769 - INFO - ==================================================\n",
      "2025-11-05 14:29:06,769 - INFO - Accuracy: 0.369 (36.9%)\n",
      "2025-11-05 14:29:06,770 - INFO - F1-Score (for 'yes' class): 0.539\n",
      "2025-11-05 14:29:06,770 - INFO - Test Set Class Distribution:\n",
      "2025-11-05 14:29:06,771 - INFO -   no: 82 samples (63.1%)\n",
      "2025-11-05 14:29:06,771 - INFO -   yes: 48 samples (36.9%)\n",
      "2025-11-05 14:29:06,772 - INFO - ==================================================\n",
      "2025-11-05 14:29:06,772 - INFO - SUMMARY\n",
      "2025-11-05 14:29:06,772 - INFO - ==================================================\n",
      "2025-11-05 14:29:06,773 - INFO - Grade Prediction MAE: 2.065 points\n",
      "2025-11-05 14:29:06,774 - INFO - Romantic Status Accuracy: 36.9%\n",
      "2025-11-05 14:29:06,774 - INFO - Romantic Status F1-Score (yes): 0.539\n",
      "2025-11-05 14:29:06,774 - INFO - ==================================================\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"=\" * 50)\n",
    "logger.info(\"G3 prediction (regression)\")\n",
    "logger.info(\"=\" * 50)\n",
    "logger.info(f\"Mean Absolute Error (MAE): {mae_G3:.3f} grade points\")\n",
    "logger.info(f\"Interpretation: On average, predictions are off by {mae_G3:.3f} points (out of 20)\")\n",
    "\n",
    "logger.info(\"\\n\" + \"=\" * 50)\n",
    "logger.info(\"Romantic prediction (classification) - many students wish they could predict this\")\n",
    "logger.info(\"=\" * 50)\n",
    "logger.info(f\"Accuracy: {accuracy_romantic:.3f} ({accuracy_romantic * 100:.1f}%)\")\n",
    "logger.info(f\"F1-Score (for 'yes' class): {f1_romantic_yes:.3f}\")\n",
    "\n",
    "logger.info(\"Test Set Class Distribution:\")\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    class_name = \"yes\" if cls == 1 else \"no\"\n",
    "    logger.info(f\"  {class_name}: {cnt} samples ({cnt / len(all_romantic_true) * 100:.1f}%)\")\n",
    "\n",
    "logger.info(\"=\" * 50)\n",
    "logger.info(\"SUMMARY\")\n",
    "logger.info(\"=\" * 50)\n",
    "logger.info(f\"Grade Prediction MAE: {mae_G3:.3f} points\")\n",
    "logger.info(f\"Romantic Status Accuracy: {accuracy_romantic * 100:.1f}%\")\n",
    "logger.info(f\"Romantic Status F1-Score (yes): {f1_romantic_yes:.3f}\")\n",
    "logger.info(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
