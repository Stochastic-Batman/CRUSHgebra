{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd01a4fc25dc3520",
   "metadata": {},
   "source": [
    "# **CRUSHgebra**\n",
    "\n",
    "The goal of this project is to design and train a single neural network that can perform two different tasks simultaneously (Multi-Task Learning).\n",
    "1. Task 1 is regression, aiming to predict the student's final grade, `G3` (a number from 0 to 20).\n",
    "2. Task 2 is classification, aiming to determine whether the student is in a `romantic` relationship or not.\n",
    "   \n",
    "This notebook fully covers all the code and experiments included in this repository through Python scripts. The interpreter used to run the code snippets in this notebook was 3.14; it was the same interpreter used for the entire project. After ensuring that you are using Python 3.14, install all the necessary libraries for this project:"
   ]
  },
  {
   "cell_type": "code",
   "id": "812f22341ae85723",
   "metadata": {
    "scrolled": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-15T10:31:32.165950Z"
    }
   },
   "source": [
    "!pip install -U matplotlib numpy pandas scikit-learn torch ucimlrepo"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9a2e82bc-19f7-4cef-8e74-eaa7cb2d0529",
   "metadata": {},
   "source": [
    "Here I will list all the imports used throughout the notebook (and project) so that I will not need to need to run any functional code snippet twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8720f73-a904-49a3-baf4-ab664ee0425c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:55.159247Z",
     "start_time": "2025-11-04T09:24:52.137583Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, f1_score, classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5df1b-a8f6-4b24-9afb-b34a92f83cfc",
   "metadata": {},
   "source": [
    "Now let's start by using UC Irvine's Python API to retrieve the \"Student Performance\" dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22131530-8fcd-45c5-8989-a3a70b8a30fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.502674Z",
     "start_time": "2025-11-04T09:24:55.171033Z"
    }
   },
   "outputs": [],
   "source": [
    "student_performance = fetch_ucirepo(name=\"Student Performance\")\n",
    "student_performance.metadata.additional_info.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7e7775f33ead7",
   "metadata": {},
   "source": [
    "### Attributes of the dataset:\n",
    "1. school: student's school (binary: \"GP\" - Gabriel Pereira or \"MS\" - Mousinho da Silveira)\n",
    "2. sex: student's sex (binary: \"F\" - female or \"M\" - male)\n",
    "3. age: student's age (numeric: from 15 to 22)\n",
    "4. address: student's home address type (binary: \"U\" - urban or \"R\" - rural)\n",
    "5. famsize: family size (binary: \"LE3\" - less or equal to 3 or \"GT3\" - greater than 3)\n",
    "6. Pstatus: parent's cohabitation status (binary: \"T\" - living together or \"A\" - apart)\n",
    "7. Medu: mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education)\n",
    "8. Fedu: father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education)\n",
    "9. Mjob: mother's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "10. Fjob: father's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "11. reason: reason to choose this school (nominal: close to \"home\", school \"reputation\", \"course\" preference or \"other\")\n",
    "12. guardian: student's guardian (nominal: \"mother\", \"father\" or \"other\")\n",
    "13. traveltime: home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "14. studytime: weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "15. failures: number of past class failures (numeric: n if $1 \\leq n <3$, else 4)\n",
    "16. schoolsup: extra educational support (binary: yes or no)\n",
    "17. famsup: family educational support (binary: yes or no)\n",
    "18. paid: extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "19. activities: extra-curricular activities (binary: yes or no)\n",
    "20. nursery: attended nursery school (binary: yes or no)\n",
    "21. higher: wants to take higher education (binary: yes or no)\n",
    "22. internet: Internet access at home (binary: yes or no)\n",
    "23. ***romantic***: with a romantic relationship (binary: yes or no) [TARGET]\n",
    "24. famrel: quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "25. freetime: free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "26. goout: going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "27. Dalc: workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "28. Walc: weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "29. health: current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "30. absences: number of school absences (numeric: from 0 to 93)\n",
    "\n",
    "These grades are related with the course subject, Math or Portuguese:\n",
    "\n",
    "31. G1: first period grade (numeric: from 0 to 20)\n",
    "31. G2: second period grade (numeric: from 0 to 20)\n",
    "32. ***G3***: final grade (numeric: from 0 to 20) [TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d0488-c913-421c-a309-ef491822abcc",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing (`preprocessing.py`)\n",
    "\n",
    "Just like the majority of machine learning models, neural network performance heavily relies on the quality of the data used to train and evaluate it. Additionally, neural networks only accept numeric data as input, so categorical data needs to be transformed into numerical format as well.\n",
    "\n",
    "Usually, one would check for missing values, but since the UCI website states that **there are no missing values** in the dataset, we can skip this step.\n",
    "\n",
    "In this order, we will:\n",
    "1. Separate target variables\n",
    "2. Perform a train/test split\n",
    "3. Encode categorical variables into numerical ones\n",
    "4. Normalize/standardize numerical variables\n",
    "\n",
    "First, we separate the target variables from the dataset. Now, grades (`G1`, `G2`, `G3`) are in `student_performance.data.targets`, while the rest are under `student_performance.data.features`.\n",
    "\n",
    "From the [webpage for the dataset](https://archive.ics.uci.edu/dataset/320/student+performance), we read:\n",
    "> Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).\n",
    "\n",
    "So we will ignore `G1` and `G2` altogether, separating `romantic`, `G3`, and all the remaining features of `student_performance.data.features`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146246e-35cd-486f-babf-fac4f65bd321",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.547413Z",
     "start_time": "2025-11-04T09:24:58.539912Z"
    }
   },
   "outputs": [],
   "source": [
    "G3 = student_performance.data.targets[\"G3\"]\n",
    "romantic = student_performance.data.features[\"romantic\"]\n",
    "X = student_performance.data.features.drop(columns=[\"romantic\"])\n",
    "y = pd.DataFrame({\"G3\": G3, \"romantic\": romantic})\n",
    "og_columns = [col for col in X.columns]\n",
    "\n",
    "# is \"romantic\" disbalanced? yes, it is\n",
    "y[\"romantic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c9889-0893-4e42-8215-679297e43b5f",
   "metadata": {},
   "source": [
    "Now, we perform a train/test split. `random_state` for reproducibility (95 for Lightning McQueen); `stratify` to ensure balanced distribution for `romantic`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc18285-6e2f-4595-b1cf-2fc8303c0f9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.605350Z",
     "start_time": "2025-11-04T09:24:58.558792Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=95, stratify=y[\"romantic\"])\n",
    "\n",
    "G3_train, G3_test = y_train[\"G3\"], y_test[\"G3\"]\n",
    "romantic_train, romantic_test = y_train[\"romantic\"], y_test[\"romantic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0230107-7a06-4dfe-bdc0-52d485306f6f",
   "metadata": {},
   "source": [
    "We will now check which of our variables are categorical and which are numerical, and then start by converting the categorical variables into numerical format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de7daac-9c47-44be-a49d-eaf52df5d9c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.625998Z",
     "start_time": "2025-11-04T09:24:58.620141Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    print(f\"{col}: {X_train[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b58ee23-62e6-439c-9b28-fa04f853f8c4",
   "metadata": {},
   "source": [
    "As we can see, for this particular dataset, the datatype for all of the categorical variables is `\"object\"`, so we can proceed with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd124907-1fab-47a5-98df-327ac6b91ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.652199Z",
     "start_time": "2025-11-04T09:24:58.646754Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "numerical_columns = []\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == \"object\":\n",
    "        categorical_columns.append(col)\n",
    "    else:\n",
    "        numerical_columns.append(col)\n",
    "\n",
    "print(categorical_columns)\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3958d-5e9b-4ea4-b4f7-d8458bf757f4",
   "metadata": {},
   "source": [
    "For both categorical and numerical variables, we fit the encoder, normalizer, or standardizer on `X_train`, and then apply the fitted method to `X_test` to prevent data leakage.\n",
    "\n",
    "As for the strategy of encoding categorical variables:\n",
    "- For binary categorical variables, binary encoding doesn't create artificial ordinal relationships. Each variable will simply map to 0 or 1.\n",
    "- For nominal variables (`Mjob`, `Fjob`, `reason`, `guardian`), one-hot encoding creates binary columns for each category, preventing the model from assuming false ordinal relationships (e.g., \"teacher\" > \"health\"). This is not an overhead, as none of these variables take more than four possible values.\n",
    "- Ordinal categorical variables are numerical features for this dataset. We standardize all numerical columns. This is necessary because even though ordinal variables have meaningful ordering, they exist on different scales (some 0-4, others 1-5, and `absences` goes 0-93), which would cause the neural network to give disproportionate weight to larger-scale features during gradient descent. Standardization puts all features on the same scale ($\\mu=0, \\sigma=1$) so the network can learn their relative importance based on predictive power, not magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c0bd3-3c4c-44ed-b13a-e03f7c501276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.713031Z",
     "start_time": "2025-11-04T09:24:58.672044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Binary categorical variables (encode as 0/1)\n",
    "binary_columns = [\"school\", \"sex\", \"address\", \"famsize\", \"Pstatus\", \"schoolsup\", \"famsup\", \"paid\", \"activities\", \"nursery\", \"higher\", \"internet\"]\n",
    "# Nominal categorical variables (one-hot encode)\n",
    "nominal_columns = [\"Mjob\", \"Fjob\", \"reason\", \"guardian\"]\n",
    "\n",
    "# Create the preprocessor\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"binary\", OrdinalEncoder(), binary_columns),\n",
    "        (\"nominal\", OneHotEncoder(drop=\"first\", sparse_output=False, handle_unknown=\"ignore\"), nominal_columns),\n",
    "        (\"numerical\", StandardScaler(), numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit on training data ONLY\n",
    "column_transformer.fit(X_train)\n",
    "\n",
    "# Transform both training and test sets\n",
    "X_train_encoded = column_transformer.transform(X_train)\n",
    "X_test_encoded = column_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e0ba96-8bfc-498b-89f0-9c6f04fe781b",
   "metadata": {},
   "source": [
    "Converting back to DataFrame for easier inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d897171-f17d-467a-abc4-5be3ccc9093f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.729020Z",
     "start_time": "2025-11-04T09:24:58.723970Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = (\n",
    "    binary_columns + \n",
    "    column_transformer.named_transformers_[\"nominal\"].get_feature_names_out(nominal_columns).tolist() +\n",
    "    numerical_columns\n",
    ")\n",
    "\n",
    "X_train_encoded = pd.DataFrame(X_train_encoded, columns=feature_names, index=X_train.index)\n",
    "X_test_encoded = pd.DataFrame(X_test_encoded, columns=feature_names, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e9d25-712c-4cae-b78c-0184de438c9b",
   "metadata": {},
   "source": [
    "Let's create a custom PyTorch dataset (`CrushSet.py`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127fc0dc-d5bf-4c07-8ff7-49829273500a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.745432Z",
     "start_time": "2025-11-04T09:24:58.739921Z"
    }
   },
   "outputs": [],
   "source": [
    "class CrushSet(Dataset):\n",
    "    def __init__(self, X: pd.DataFrame, y: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Create a dataset for heartbroken nerds. (Not for me I swear, I have the most beautiful and loving girlfriend in the history of the world)\n",
    "\n",
    "        Args:\n",
    "            X: (n_samples, n_features) -> preprocessed features\n",
    "            y: (n_samples, 2) -> targets DataFrame containing both 'G3' and 'romantic' columns\n",
    "        \"\"\"\n",
    "        self.X = torch.FloatTensor(X.values)\n",
    "        self.y_G3 = torch.FloatTensor(y[\"G3\"].values)\n",
    "        self.y_romantic = torch.LongTensor((y[\"romantic\"] == \"yes\").astype(int).values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns three items: (x_data, y_G3_data, y_romantic_data)\n",
    "\n",
    "        Returns:\n",
    "            x_data: feature vector, shape (n_features,)\n",
    "            y_G3_data: grade target (scalar)\n",
    "            y_romantic_data: romantic status target (0 or 1)\n",
    "        \"\"\"\n",
    "        return self.X[idx], self.y_G3[idx], self.y_romantic[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a187b3d-8450-43f7-ad70-41523ab05d0a",
   "metadata": {},
   "source": [
    "Completing train/test/validation split and creating DataLoaders (this snippet of code is implemented in `train.py`, which we'll cover later, but here we can avoid saving the split results and reloading them.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90bbf87-7525-44cf-a049-54c78ca1095e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.764777Z",
     "start_time": "2025-11-04T09:24:58.755356Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split train into train and validation sets (80/20 split of training data)\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_encoded, y_train, test_size=0.2, random_state=95, stratify=y_train[\"romantic\"])\n",
    "\n",
    "# Create Dataset instances\n",
    "train_dataset = CrushSet(X_train_final, y_train_final)\n",
    "test_dataset = CrushSet(X_test_encoded, y_test)\n",
    "val_dataset = CrushSet(X_val, y_val)\n",
    "\n",
    "# Create DataLoaders\n",
    "BS = 32  # yeah, let's go with the default batch size\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab7865f-0fba-4df2-8245-cba9be0a1a79",
   "metadata": {},
   "source": [
    "## Part 2: Building the Multi-Head Model (`TwoRabbitsHunter.py`)\n",
    "\n",
    "In this task, we will create a single neural network with a shared feature-extractor(\"body\") and two task-specific output modules(\"heads\").\n",
    "\n",
    "- Shared body: a feedforward feature extractor that transforms input features into a compact shared representation using repeated blocks of linear projection, nonlinearity, normalization, and regularization. This body is responsible for learning the common student-profile features useful to both tasks.\n",
    "\n",
    "- First Head: Grade prediction (regression) - a small feedforward module that takes the shared representation and produces one continuous scalar - the predicted grade.\n",
    "\n",
    "- Second Head: Romantic status (classification) - a small feedforward module that takes the same shared representation and produces two output scores (logits) corresponding to the \"yes\"/\"no\" classes.\n",
    "\n",
    "- Data flow: inputs go into the shared body; its output is forwarded in parallel to both heads; the model returns both the scalar regression output and the two-class logits.\n",
    "\n",
    "I will name the class `TwoRabbitsHunter`, after a Georgian saying that roughly translates to: \n",
    ">A hunter who chases two rabbits will catch neither."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b96e33a80e0c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.780575Z",
     "start_time": "2025-11-04T09:24:58.774134Z"
    }
   },
   "outputs": [],
   "source": [
    "class TwoRabbitsHunter(nn.Module):\n",
    "    HEAD_SIZE = 6\n",
    "    \n",
    "    def __init__(self, input_size=38, hidden_size=16, shared_output_size=8, dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        Class to simultaneously predict G3 (regression) and romantic (classification)\n",
    "\n",
    "        Args:\n",
    "            input_size: Number of input features (X_train_encoded.shape[1] == 38)\n",
    "            hidden_size: Size of hidden layers in shared body\n",
    "            shared_output_size: Size of final shared representation\n",
    "            dropout_rate: Dropout probability for regularization\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # shared body\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_size, shared_output_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm1d(shared_output_size)  # this is where the shared body ends\n",
    "\n",
    "        # regression head\n",
    "        self.G3_fc1 = nn.Linear(shared_output_size, self.HEAD_SIZE)\n",
    "        self.G3_relu = nn.ReLU()\n",
    "        self.G3_bn = nn.BatchNorm1d(self.HEAD_SIZE)\n",
    "        self.G3_dropout = nn.Dropout(dropout_rate)\n",
    "        self.G3_fc2 = nn.Linear(self.HEAD_SIZE, 1)  # G3\n",
    "\n",
    "        # classification head\n",
    "        self.romantic_fc1 = nn.Linear(shared_output_size, self.HEAD_SIZE)\n",
    "        self.romantic_relu = nn.ReLU()\n",
    "        self.romantic_bn = nn.BatchNorm1d(self.HEAD_SIZE)\n",
    "        self.romantic_dropout = nn.Dropout(dropout_rate)\n",
    "        self.romantic_fc2 = nn.Linear(self.HEAD_SIZE, 2)  # romantic logits (\"yes\"/\"no\")\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.bn1(self.relu1(self.fc1(x))))\n",
    "        x = self.bn2(self.relu2(self.fc2(x)))\n",
    "\n",
    "        G3_pred = self.G3_fc2(self.G3_dropout(self.G3_bn(self.G3_relu(self.G3_fc1(x)))))\n",
    "        romantic_logits = self.romantic_fc2(self.romantic_dropout(self.romantic_bn(self.romantic_relu(self.romantic_fc1(x)))))\n",
    "\n",
    "        return G3_pred, romantic_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7188d3e-6c72-494f-9acc-6c4b86827de2",
   "metadata": {},
   "source": [
    "As `X_train_encoded.shape = (519, 38)`, a compact two-layer shared body ($38 \\to 16 \\to $ `HEAD_SIZE`) prevents overfitting while maintaining sufficient representational capacity. The parameter count of $\\approx 1,500$ aligns better with the dataset size compared to deeper alternatives. Each head uses a single hidden layer of `HEAD_SIZE` neurons before outputting predictions. A single dropout layer after the first shared layer provides regularization at the point of highest dimensionality where overfitting risk is greatest, while the second layer's batch normalization alone sufficiently regularizes the smaller `HEAD_SIZE`-dimensional representation that feeds into both specialized heads. Dropout rate of $0.2$ is a classic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b7f12f-9236-4e52-b6c8-11a554ff074e",
   "metadata": {},
   "source": [
    "## Part 3: The Custom Training Loop (`train.py`)\n",
    "\n",
    "We will implement a training and validation procedure tailored for a multi-task model with two separate objectives.\n",
    "\n",
    "Training loop:\n",
    "- Define two appropriate loss functions: one for the regression task and one for the classification task.\n",
    "- For each training batch, run a forward pass and obtain two outputs from the model: the regression prediction and the classification logits.\n",
    "- Compute each task's loss separately using the corresponding predictions and targets, taking care that targets and predictions have the correct shapes and types for each loss.\n",
    "- Combine the two task losses into a single scalar `total_loss` (for example by summing them, or using weighted sum if we choose to weight tasks differently).\n",
    "- Backpropagate once on `total_loss` so gradients flow through both heads and the shared body together.\n",
    "- Update model parameters based on the aggregated gradients.\n",
    "\n",
    "Validation loop:\n",
    "- Run the model on validation data in evaluation mode and obtain both outputs per batch.\n",
    "- Compute each task's validation loss separately, accumulate them across the validation set, and report both validation losses (and optionally their combined value).\n",
    "- Use these validation losses to monitor training progress and for early stopping or hyperparameter decisions.\n",
    "\n",
    "But before the loops, let's configure logger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7c876-99b9-4605-94fe-d41a60d16768",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:24:58.794218Z",
     "start_time": "2025-11-04T09:24:58.790383Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d7627-6839-47f1-92fa-2e8e6f4913a2",
   "metadata": {},
   "source": [
    "For the sake of training the model for different values of $\\alpha$, I have to put everything together in a single `train_model(alpha)` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac018c378a53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(alpha, X_train_final, y_train_final, X_val, y_val, X_test_encoded, y_test):\n",
    "    logger.info(\"=\" * 50)\n",
    "    logger.info(f\"Training model with alpha = {alpha}\")\n",
    "    logger.info(\"=\" * 50)\n",
    "\n",
    "    # create Dataset instances using provided data\n",
    "    train_dataset = CrushSet(X_train_final, y_train_final)\n",
    "    test_dataset = CrushSet(X_test_encoded, y_test)\n",
    "    val_dataset = CrushSet(X_val, y_val)\n",
    "\n",
    "    # create DataLoaders\n",
    "    BS = 32\n",
    "\n",
    "    # compute weights for class imbalance\n",
    "    romantic_labels = [int(y) for _, _, y in train_dataset]\n",
    "    class_counts = Counter(romantic_labels)\n",
    "    total = sum(class_counts.values())\n",
    "    weights = [total / class_counts[i] for i in range(2)]\n",
    "    sample_weights = [weights[y] for y in romantic_labels]\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BS, sampler=sampler)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False)\n",
    "\n",
    "    # model initialization\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TwoRabbitsHunter(input_size=X_train_final.shape[1]).to(device)\n",
    "\n",
    "    regression_loss_fn = nn.MSELoss()\n",
    "    class_weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
    "    classification_loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    learning_rate = 0.0005\n",
    "    weight_decay = 1e-4\n",
    "    epochs = 500\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    logger.info(f\"Alpha (G3 weight): {alpha}\")\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    # lists to track metrics for plotting\n",
    "    train_total_losses = []\n",
    "    train_G3_losses = []\n",
    "    train_romantic_losses = []\n",
    "    val_total_losses = []\n",
    "    val_G3_losses = []\n",
    "    val_romantic_losses = []\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_G3_loss = 0.0\n",
    "        train_romantic_loss = 0.0\n",
    "        train_total_loss = 0.0\n",
    "        train_batches = 0.0\n",
    "\n",
    "        for batch_X, batch_G3, batch_romantic in train_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_G3 = batch_G3.to(device)\n",
    "            batch_romantic = batch_romantic.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            G3_pred, romantic_logits = model(batch_X)\n",
    "\n",
    "            G3_loss = regression_loss_fn(G3_pred.squeeze(), batch_G3)\n",
    "            romantic_loss = classification_loss_fn(romantic_logits, batch_romantic)\n",
    "            total_loss = alpha * G3_loss + (1 - alpha) * romantic_loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_G3_loss += G3_loss.item()\n",
    "            train_romantic_loss += romantic_loss.item()\n",
    "            train_total_loss += total_loss.item()\n",
    "            train_batches += 1\n",
    "\n",
    "        avg_train_G3 = train_G3_loss / train_batches\n",
    "        avg_train_romantic = train_romantic_loss / train_batches\n",
    "        avg_train_total = train_total_loss / train_batches\n",
    "\n",
    "        train_total_losses.append(avg_train_total)\n",
    "        train_G3_losses.append(avg_train_G3)\n",
    "        train_romantic_losses.append(avg_train_romantic)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_G3_loss = 0.0\n",
    "        val_romantic_loss = 0.0\n",
    "        val_total_loss = 0.0\n",
    "        val_batches = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_G3, batch_romantic in val_loader:\n",
    "                batch_X = batch_X.to(device)\n",
    "                batch_G3 = batch_G3.to(device)\n",
    "                batch_romantic = batch_romantic.to(device)\n",
    "\n",
    "                G3_pred, romantic_logits = model(batch_X)\n",
    "\n",
    "                G3_loss = regression_loss_fn(G3_pred.squeeze(), batch_G3)\n",
    "                romantic_loss = classification_loss_fn(romantic_logits, batch_romantic)\n",
    "                total_loss = alpha * G3_loss + (1 - alpha) * romantic_loss\n",
    "\n",
    "                val_G3_loss += G3_loss.item()\n",
    "                val_romantic_loss += romantic_loss.item()\n",
    "                val_total_loss += total_loss.item()\n",
    "                val_batches += 1\n",
    "\n",
    "        avg_val_total = val_total_loss / val_batches\n",
    "        avg_val_G3 = val_G3_loss / val_batches\n",
    "        avg_val_romantic = val_romantic_loss / val_batches\n",
    "\n",
    "        val_total_losses.append(avg_val_total)\n",
    "        val_G3_losses.append(avg_val_G3)\n",
    "        val_romantic_losses.append(avg_val_romantic)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            logger.info(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "            logger.info(f\"  Train -> Total: {avg_train_total:.3f}, G3: {avg_train_G3:.3f}, Romantic: {avg_train_romantic:.3f}\")\n",
    "            logger.info(f\"  Val -> Total: {avg_val_total:.3f}, G3: {avg_val_G3:.3f}, Romantic: {avg_val_romantic:.3f}\")\n",
    "\n",
    "    # don't save model - as opposed to `train.py` - return it directly\n",
    "    logger.info(f\"Training completed for alpha={alpha}\")\n",
    "\n",
    "    metrics: dict[str, list[float]] = {\n",
    "        'train_total': train_total_losses,\n",
    "        'train_G3': train_G3_losses,\n",
    "        'train_romantic': train_romantic_losses,\n",
    "        'val_total': val_total_losses,\n",
    "        'val_G3': val_G3_losses,\n",
    "        'val_romantic': val_romantic_losses,\n",
    "        'class_weights': weights\n",
    "    }\n",
    "\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60bdc3e2ec69ad2",
   "metadata": {},
   "source": [
    "Now, let's use the method above $\\forall \\alpha \\in \\{0.3, 0.5, 0.7\\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1515585d49d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = [0.3, 0.5, 0.7]\n",
    "models = {}\n",
    "model_metrics = {}\n",
    "\n",
    "for i, alpha in enumerate(alpha_values):\n",
    "    models[alpha], model_metrics[alpha] = train_model(alpha, X_train_final, y_train_final, X_val, y_val, X_test_encoded, y_test)\n",
    "\n",
    "logger.info(\"All training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3486a9c-599e-4af9-83d3-d0775a0659cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T09:25:38.250400Z",
     "start_time": "2025-11-04T09:25:38.247607Z"
    }
   },
   "source": [
    "## Part 4: Evaluation & Analysis\n",
    "\n",
    "A single \"accuracy\" score is meaningless. We must evaluate each task's performance on test set. \n",
    "\n",
    "- For `G3` prediction:\n",
    "  - We report the Mean Absolute Error (MAE). This tells us, \"On average, how many grade points was our model's prediction off by?\". We use MAE because its scale is more intuitive than MSE's (humans tend to comprehend the average difference in grade points better than the squared metric of MSE).\n",
    "  \n",
    "- For `romantic` prediction:\n",
    "  - We report accuracy.\n",
    "  - Additionally, we report the F1-Score (for the \"yes\" class). This is crucial, as the classes are imbalanced and it balances precision and recall.\n",
    "\n",
    "Again, for the sake of evaluating for different values of $\\alpha$, I will put everything together in one method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a61fff-95fe-4ef8-86f1-5fc2a0cfa903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(alpha):\n",
    "    logger.info(\"=\" * 50)\n",
    "    logger.info(f\"Evaluating model with alpha = {alpha}\")\n",
    "    logger.info(\"=\" * 50)\n",
    "\n",
    "    model = TwoRabbitsHunter(input_size=X_test_encoded.shape[1]).to(device)\n",
    "    model.load_state_dict(torch.load(f\"tmp/TwoRabbitsHunter_{alpha}.pth\", map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    regression_loss_fn = nn.MSELoss()\n",
    "    with open(f\"tmp/metrics_alpha_{alpha}.pkl\", 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "    class_weights = torch.tensor(train_data.get('class_weights', [1.0, 1.0]), dtype=torch.float).to(device)\n",
    "    classification_loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    all_G3_preds = []\n",
    "    all_G3_true = []\n",
    "    all_romantic_preds = []\n",
    "    all_romantic_true = []\n",
    "\n",
    "    test_total_losses = []\n",
    "    test_G3_losses = []\n",
    "    test_romantic_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_G3, batch_romantic in test_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_G3 = batch_G3.to(device)\n",
    "            batch_romantic = batch_romantic.to(device)\n",
    "\n",
    "            G3_pred, romantic_logits = model(batch_X)\n",
    "\n",
    "            G3_loss = regression_loss_fn(G3_pred.squeeze(), batch_G3)\n",
    "            romantic_loss = classification_loss_fn(romantic_logits, batch_romantic)\n",
    "            total_loss = alpha * G3_loss + (1 - alpha) * romantic_loss\n",
    "\n",
    "            test_total_losses.append(total_loss.item())\n",
    "            test_G3_losses.append(G3_loss.item())\n",
    "            test_romantic_losses.append(romantic_loss.item())\n",
    "\n",
    "            all_G3_preds.extend(G3_pred.squeeze().cpu().numpy())\n",
    "            all_G3_true.extend(batch_G3.cpu().numpy())\n",
    "\n",
    "            romantic_pred_classes = torch.argmax(romantic_logits, dim=1)\n",
    "            all_romantic_preds.extend(romantic_pred_classes.cpu().numpy())\n",
    "            all_romantic_true.extend(batch_romantic.cpu().numpy())\n",
    "\n",
    "    avg_test_total = sum(test_total_losses) / len(test_total_losses)\n",
    "    avg_test_G3 = sum(test_G3_losses) / len(test_G3_losses)\n",
    "    avg_test_romantic = sum(test_romantic_losses) / len(test_romantic_losses)\n",
    "\n",
    "    all_G3_preds = np.array(all_G3_preds)\n",
    "    all_G3_true = np.array(all_G3_true)\n",
    "    all_romantic_preds = np.array(all_romantic_preds)\n",
    "    all_romantic_true = np.array(all_romantic_true)\n",
    "\n",
    "    mae_G3 = mean_absolute_error(all_G3_true, all_G3_preds)\n",
    "    accuracy_romantic = accuracy_score(all_romantic_true, all_romantic_preds)\n",
    "    f1_romantic_yes = f1_score(all_romantic_true, all_romantic_preds, pos_label=1)\n",
    "    f1_romantic_no = f1_score(all_romantic_true, all_romantic_preds, pos_label=0)\n",
    "    unique, counts = np.unique(all_romantic_true, return_counts=True)\n",
    "\n",
    "    logger.info(\"Test Set Class Distribution:\")\n",
    "    for cls, cnt in zip(unique, counts):\n",
    "        class_name = \"yes\" if cls == 1 else \"no\"\n",
    "        logger.info(f\"  {class_name}: {cnt} samples ({cnt / len(all_romantic_true) * 100:.1f}%)\")\n",
    "\n",
    "    logger.info(\"=\" * 50)\n",
    "    logger.info(f\"SUMMARY FOR ALPHA = {alpha}\")\n",
    "    logger.info(\"=\" * 50)\n",
    "    logger.info(f\"G3 Prediction MAE: {mae_G3:.3f} points\")\n",
    "    logger.info(f\"Interpretation: On average, predictions are off by {mae_G3:.3f} points (out of 20)\")\n",
    "    logger.info(f\"Romantic Accuracy: {accuracy_romantic:.3f} ({accuracy_romantic * 100:.1f}%)\")\n",
    "    logger.info(f\"Romantic F1-Score for 'yes' class: {f1_romantic_yes:.3f}\")\n",
    "    logger.info(f\"Romantic F1-Score for 'no' class: {f1_romantic_no:.3f}\")\n",
    "    logger.info(\"=\" * 50)\n",
    "\n",
    "    metrics: dict[str, float | list[float] | dict] = {\n",
    "        'test_total_loss': avg_test_total,\n",
    "        'test_G3_loss': avg_test_G3,\n",
    "        'test_romantic_loss': avg_test_romantic,\n",
    "        'test_total_losses': test_total_losses,\n",
    "        'test_G3_losses': test_G3_losses,\n",
    "        'test_romantic_losses': test_romantic_losses,\n",
    "        'mae_G3': mae_G3,\n",
    "        'accuracy_romantic': accuracy_romantic,\n",
    "        'f1_romantic_yes': f1_romantic_yes,\n",
    "        'f1_romantic_no': f1_romantic_no,\n",
    "        'class_distribution': dict(zip(unique, counts))\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b614a-909b-40bc-b4f9-f39666902dbc",
   "metadata": {},
   "source": [
    "We also need plotting method. I used DeepSeek to write this method, as I am not great at plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5809268d-10d6-417d-80a8-e7ea7c5aaa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_vs_test_comparison(alpha, test_metrics, save_plot=True):\n",
    "    try:\n",
    "        with open(f\"tmp/metrics_alpha_{alpha}.pkl\", 'rb') as f:\n",
    "            train_data = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Metrics file for alpha={alpha} not found. Run training first.\")\n",
    "        return\n",
    "\n",
    "    plt.style.use('dark_background')\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    epochs = range(1, len(train_data['train_total']) + 1)\n",
    "    \n",
    "    axes[0].plot(epochs, train_data['train_total'], 'purple', linewidth=2, label='Training')\n",
    "    axes[0].plot(epochs, train_data['val_total'], 'lime', linewidth=2, label='Validation')\n",
    "    axes[0].axhline(y=test_metrics['test_total_loss'], color='cyan', linestyle='--', linewidth=2, label='Test')\n",
    "    axes[0].set_title(f'Total Loss (Alpha={alpha})')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(epochs, train_data['train_G3'], 'purple', linewidth=2, label='Training')\n",
    "    axes[1].plot(epochs, train_data['val_G3'], 'lime', linewidth=2, label='Validation')\n",
    "    axes[1].axhline(y=test_metrics['test_G3_loss'], color='cyan', linestyle='--', linewidth=2, label='Test')\n",
    "    axes[1].set_title(f'G3 Loss (Alpha={alpha})')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[2].plot(epochs, train_data['train_romantic'], 'purple', linewidth=2, label='Training')\n",
    "    axes[2].plot(epochs, train_data['val_romantic'], 'lime', linewidth=2, label='Validation')\n",
    "    axes[2].axhline(y=test_metrics['test_romantic_loss'], color='cyan', linestyle='--', linewidth=2, label='Test')\n",
    "    axes[2].set_title(f'Romantic Loss (Alpha={alpha})')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Loss')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_plot:\n",
    "        os.makedirs('tmp', exist_ok=True)\n",
    "        plot_filename = f\"tmp/train_val_test_losses_alpha_{alpha}.png\"\n",
    "        plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        logger.info(f\"Training vs Validation vs Test loss curves saved to '{plot_filename}'\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    final_train = {\n",
    "        'total_loss': train_data['train_total'][-1],\n",
    "        'G3_loss': train_data['train_G3'][-1],\n",
    "        'romantic_loss': train_data['train_romantic'][-1]\n",
    "    }\n",
    "    final_val = {\n",
    "        'total_loss': train_data['val_total'][-1],\n",
    "        'G3_loss': train_data['val_G3'][-1],\n",
    "        'romantic_loss': train_data['val_romantic'][-1]\n",
    "    }\n",
    "\n",
    "    logger.info(\"=\" * 60)\n",
    "    logger.info(f\"FINAL LOSS COMPARISON FOR ALPHA = {alpha}\")\n",
    "    logger.info(\"=\" * 60)\n",
    "    logger.info(\"Total Loss:\")\n",
    "    logger.info(f\"  Training: {final_train['total_loss']:.3f}\")\n",
    "    logger.info(f\"  Validation: {final_val['total_loss']:.3f}\")\n",
    "    logger.info(f\"  Test: {test_metrics['test_total_loss']:.3f}\")\n",
    "    logger.info(\"G3 Loss:\")\n",
    "    logger.info(f\"  Training: {final_train['G3_loss']:.3f}\")\n",
    "    logger.info(f\"  Validation: {final_val['G3_loss']:.3f}\")\n",
    "    logger.info(f\"  Test: {test_metrics['test_G3_loss']:.3f}\")\n",
    "    logger.info(\"Romantic Loss:\")\n",
    "    logger.info(f\"  Training: {final_train['romantic_loss']:.3f}\")\n",
    "    logger.info(f\"  Validation: {final_val['romantic_loss']:.3f}\")\n",
    "    logger.info(f\"  Test: {test_metrics['test_romantic_loss']:.3f}\")\n",
    "    logger.info(\"=\" * 60)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95da94-1569-4ac6-b8ce-55e29b25ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = [0.3, 0.5, 0.7]\n",
    "evaluated_metrics = {}  # not really useful rn\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    test_metrics = evaluate_model(alpha)\n",
    "    evaluated_metrics[alpha] = test_metrics\n",
    "    plot_train_vs_test_comparison(alpha, test_metrics, save_plot=True)\n",
    "\n",
    "logger.info(\"All evaluation and comparison plotting completed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8179b401-4690-4274-a30f-c5a64b4e826f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Based on the evaluation of three multi-task models with different alpha values - the parameter that balances the weight between the grade regression (`G3`) and romance classification tasks - a clear performance hierarchy is established, with $\\alpha=0.5$ emerging as the optimal configuration.\n",
    "\n",
    "The model with $\\alpha=0.3$ places less emphasis on the grade prediction task. This results in the highest test MAE of $2.066$ for grades and a higher total test loss compared to $\\alpha=0.5$, suggesting its weighting is suboptimal for the primary objective.\n",
    "\n",
    "The model with $\\alpha=0.5$ demonstrates the best balance. It achieves the lowest Grade Prediction MAE of $1.931$ on the test set, indicating the most accurate forecasts. Its total test loss of $3.735$ is the lowest among all models, and it exhibits a healthy generalization pattern where validation and test losses are lower than training loss. This indicates that the auxiliary romance task, while not producing meaningful classifications itself, provides a beneficial regularization effect at this weight.\n",
    "\n",
    "Conversely, the model with $\\alpha=0.7$ heavily prioritizes the grade task. However, this leads to overfitting, evidenced by its significantly higher total test loss of $5.099$. While its grade MAE of $1.943$ is better than $\\alpha=0.3$, it is still worse than $\\alpha=0.5$. The romantic loss also shows a larger gap between training and test performance, further confirming overfitting. This implies that completely overshadowing the auxiliary task removes its regularizing benefit, degrading overall model robustness.\n",
    "\n",
    "In conclusion, while the romance classifier failed universally, its influence as a regularizer is crucial. The balanced weighting at $\\alpha=0.5$ provides the ideal compromise, yielding the most accurate and generalizable model for the primary task of grade prediction, making it the definitive best choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
