{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd01a4fc25dc3520",
   "metadata": {},
   "source": [
    "# **CRUSHgebra**\n",
    "\n",
    "The goal of this project is to design and train a single neural network that can perform two different tasks simultaneously (Multi-Task Learning).\n",
    "1. Task 1 is regression, aiming to predict the student's final grade, `G3` (a number from 0 to 20).\n",
    "2. Task 2 is classification, aiming to determine whether the student is in a `romantic` relationship or not.\n",
    "   \n",
    "This notebook fully covers all the code and experiments included in this repository through Python scripts. The interpreter used to run the code snippets in this notebook was 3.14; it was the same interpreter used for the entire project. After ensuring that you are using Python 3.14, install all the necessary libraries for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812f22341ae85723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T16:42:56.360340Z",
     "start_time": "2025-11-02T16:42:51.394293Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: torch in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: ucimlrepo in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from ucimlrepo) (2025.10.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ladoturmanidze\\crushgebra\\crushgebra_venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pandas scikit-learn torch ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2e82bc-19f7-4cef-8e74-eaa7cb2d0529",
   "metadata": {},
   "source": [
    "Here I will list all the imports used throughout the notebook (and project) so that I will not need to need to run any functional code snippet twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8720f73-a904-49a3-baf4-ab664ee0425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5df1b-a8f6-4b24-9afb-b34a92f83cfc",
   "metadata": {},
   "source": [
    "Now let's start by using UC Irvine's Python API to retrieve the \"Student Performance\" dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22131530-8fcd-45c5-8989-a3a70b8a30fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_performance = fetch_ucirepo(name='Student Performance')\n",
    "student_performance.metadata.additional_info.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7e7775f33ead7",
   "metadata": {},
   "source": [
    "### Attributes of the dataset:\n",
    "1. school: student's school (binary: \"GP\" - Gabriel Pereira or \"MS\" - Mousinho da Silveira)\n",
    "2. sex: student's sex (binary: \"F\" - female or \"M\" - male)\n",
    "3. age: student's age (numeric: from 15 to 22)\n",
    "4. address: student's home address type (binary: \"U\" - urban or \"R\" - rural)\n",
    "5. famsize: family size (binary: \"LE3\" - less or equal to 3 or \"GT3\" - greater than 3)\n",
    "6. Pstatus: parent's cohabitation status (binary: \"T\" - living together or \"A\" - apart)\n",
    "7. Medu: mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education)\n",
    "8. Fedu: father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education)\n",
    "9. Mjob: mother's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "10. Fjob: father's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n",
    "11. reason: reason to choose this school (nominal: close to \"home\", school \"reputation\", \"course\" preference or \"other\")\n",
    "12. guardian: student's guardian (nominal: \"mother\", \"father\" or \"other\")\n",
    "13. traveltime: home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n",
    "14. studytime: weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "15. failures: number of past class failures (numeric: n if $1 \\leq n <3$, else 4)\n",
    "16. schoolsup: extra educational support (binary: yes or no)\n",
    "17. famsup: family educational support (binary: yes or no)\n",
    "18. paid: extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n",
    "19. activities: extra-curricular activities (binary: yes or no)\n",
    "20. nursery: attended nursery school (binary: yes or no)\n",
    "21. higher: wants to take higher education (binary: yes or no)\n",
    "22. internet: Internet access at home (binary: yes or no)\n",
    "23. ***romantic***: with a romantic relationship (binary: yes or no) [TARGET]\n",
    "24. famrel: quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "25. freetime: free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "26. goout: going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "27. Dalc: workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "28. Walc: weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "29. health: current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "30. absences: number of school absences (numeric: from 0 to 93)\n",
    "\n",
    "These grades are related with the course subject, Math or Portuguese:\n",
    "\n",
    "31. G1: first period grade (numeric: from 0 to 20)\n",
    "31. G2: second period grade (numeric: from 0 to 20)\n",
    "32. ***G3***: final grade (numeric: from 0 to 20) [TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d0488-c913-421c-a309-ef491822abcc",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing (`preprocessing.py`)\n",
    "\n",
    "Just like the majority of machine learning models, neural network performance heavily relies on the quality of the data used to train and evaluate it. Additionally, neural networks only accept numeric data as input, so categorical data needs to be transformed into numerical format as well.\n",
    "\n",
    "Usually, one would check for missing values, but since the UCI website states that **there are no missing values** in the dataset, we can skip this step.\n",
    "\n",
    "In this order, we will:\n",
    "1. Separate target variables\n",
    "2. Perform a train/test split\n",
    "3. Encode categorical variables into numerical ones\n",
    "4. Normalize/standardize numerical variables\n",
    "\n",
    "First, we separate the target variables from the dataset. Now, grades (`G1`, `G2`, `G3`) are in `student_performance.data.targets`, while the rest are under `student_performance.data.features`.\n",
    "\n",
    "From the [webpage for the dataset](https://archive.ics.uci.edu/dataset/320/student+performance), we read:\n",
    "> Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).\n",
    "\n",
    "So we will ignore `G1` and `G2` altogether, separating `romantic`, `G3`, and all the remaining features of `student_performance.data.features`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2146246e-35cd-486f-babf-fac4f65bd321",
   "metadata": {},
   "outputs": [],
   "source": [
    "G3 = student_performance.data.targets[\"G3\"]\n",
    "romantic = student_performance.data.features[\"romantic\"]\n",
    "X = student_performance.data.features.drop(columns=[\"romantic\"])\n",
    "y = pd.DataFrame({'G3': G3, 'romantic': romantic})\n",
    "og_columns = [col for col in X.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c9889-0893-4e42-8215-679297e43b5f",
   "metadata": {},
   "source": [
    "Now, we perform a train/test split. `random_state` for reproducibility (95 for Lightning McQueen); `stratify` to ensure balanced distribution for `romantic`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc18285-6e2f-4595-b1cf-2fc8303c0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=95, stratify=y['romantic'])\n",
    "\n",
    "G3_train, G3_test = y_train['G3'], y_test['G3']\n",
    "romantic_train, romantic_test = y_train['romantic'], y_test['romantic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0230107-7a06-4dfe-bdc0-52d485306f6f",
   "metadata": {},
   "source": [
    "We will now check which of our variables are categorical and which are numerical, and then start by converting the categorical variables into numerical format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de7daac-9c47-44be-a49d-eaf52df5d9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school: object\n",
      "sex: object\n",
      "age: int64\n",
      "address: object\n",
      "famsize: object\n",
      "Pstatus: object\n",
      "Medu: int64\n",
      "Fedu: int64\n",
      "Mjob: object\n",
      "Fjob: object\n",
      "reason: object\n",
      "guardian: object\n",
      "traveltime: int64\n",
      "studytime: int64\n",
      "failures: int64\n",
      "schoolsup: object\n",
      "famsup: object\n",
      "paid: object\n",
      "activities: object\n",
      "nursery: object\n",
      "higher: object\n",
      "internet: object\n",
      "famrel: int64\n",
      "freetime: int64\n",
      "goout: int64\n",
      "Dalc: int64\n",
      "Walc: int64\n",
      "health: int64\n",
      "absences: int64\n"
     ]
    }
   ],
   "source": [
    "for col in X_train.columns:\n",
    "    print(f\"{col}: {X_train[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b58ee23-62e6-439c-9b28-fa04f853f8c4",
   "metadata": {},
   "source": [
    "As we can see, for this particular dataset, the datatype for all of the categorical variables is `\"object\"`, so we can proceed with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd124907-1fab-47a5-98df-327ac6b91ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet']\n",
      "['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = []\n",
    "numerical_columns = []\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == \"object\":\n",
    "        categorical_columns.append(col)\n",
    "    else:\n",
    "        numerical_columns.append(col)\n",
    "\n",
    "print(categorical_columns)\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3958d-5e9b-4ea4-b4f7-d8458bf757f4",
   "metadata": {},
   "source": [
    "For both categorical and numerical variables, we fit the encoder, normalizer, or standardizer on `X_train`, and then apply the fitted method to `X_test` to prevent data leakage.\n",
    "\n",
    "As for the strategy of encoding categorical variables:\n",
    "- For binary categorical variables, binary encoding doesn't create artificial ordinal relationships. Each variable will simply map to 0 or 1.\n",
    "- For nominal variables (`Mjob`, `Fjob`, `reason`, `guardian`), one-hot encoding creates binary columns for each category, preventing the model from assuming false ordinal relationships (e.g., \"teacher\" > \"health\"). This is not an overhead, as none of these variables take more than four possible values.\n",
    "- Ordinal categorical variables are numerical features for this dataset. We standardize all numerical columns. This is necessary because even though ordinal variables have meaningful ordering, they exist on different scales (some 0-4, others 1-5, and `absences` goes 0-93), which would cause the neural network to give disproportionate weight to larger-scale features during gradient descent. Standardization puts all features on the same scale ($\\mu=0, \\sigma=1$) so the network can learn their relative importance based on predictive power, not magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c70c0bd3-3c4c-44ed-b13a-e03f7c501276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary categorical variables (encode as 0/1)\n",
    "binary_columns = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet']\n",
    "# Nominal categorical variables (one-hot encode)\n",
    "nominal_columns = ['Mjob', 'Fjob', 'reason', 'guardian']\n",
    "\n",
    "# Create the preprocessor\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('binary', OrdinalEncoder(), binary_columns),\n",
    "        ('nominal', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), nominal_columns),\n",
    "        ('numerical', StandardScaler(), numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit on training data ONLY\n",
    "column_transformer.fit(X_train)\n",
    "\n",
    "# Transform both training and test sets\n",
    "X_train_encoded = column_transformer.transform(X_train)\n",
    "X_test_encoded = column_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e0ba96-8bfc-498b-89f0-9c6f04fe781b",
   "metadata": {},
   "source": [
    "Converting back to DataFrame for easier inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d897171-f17d-467a-abc4-5be3ccc9093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = (\n",
    "    binary_columns + \n",
    "    column_transformer.named_transformers_['nominal'].get_feature_names_out(nominal_columns).tolist() +\n",
    "    numerical_columns\n",
    ")\n",
    "\n",
    "X_train_encoded = pd.DataFrame(X_train_encoded, columns=feature_names, index=X_train.index)\n",
    "X_test_encoded = pd.DataFrame(X_test_encoded, columns=feature_names, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e9d25-712c-4cae-b78c-0184de438c9b",
   "metadata": {},
   "source": [
    "Let's create a custom PyTorch dataset (`CrushSet.py`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "127fc0dc-d5bf-4c07-8ff7-49829273500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrushSet(Dataset):\n",
    "    def __init__(self, X: pd.DataFrame, y: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Create a dataset for heartbroken nerds. (Not for me I swear, I have the most beautiful and loving girlfriend in the history of the world)\n",
    "\n",
    "        Args:\n",
    "            X: (n_samples, n_features) -> preprocessed features\n",
    "            y: (n_samples, 2) -> targets DataFrame containing both 'G3' and 'romantic' columns\n",
    "        \"\"\"\n",
    "        self.X = torch.FloatTensor(X.values)\n",
    "        self.y_grade = torch.FloatTensor(y['G3'].values)\n",
    "        self.y_romantic = torch.LongTensor((y['romantic'] == 'yes').astype(int).values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns three items: (x_data, y_grade_data, y_romantic_data)\n",
    "\n",
    "        Returns:\n",
    "            x_data: feature vector, shape (n_features,)\n",
    "            y_grade_data: grade target (scalar)\n",
    "            y_romantic_data: romantic status target (0 or 1)\n",
    "        \"\"\"\n",
    "        return self.X[idx], self.y_grade[idx], self.y_romantic[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a187b3d-8450-43f7-ad70-41523ab05d0a",
   "metadata": {},
   "source": [
    "Completing train/test/validation split and creating DataLoaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c90bbf87-7525-44cf-a049-54c78ca1095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train into train and validation sets (80/20 split of training data)\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_encoded, y_train, test_size=0.2, random_state=95, stratify=y_train['romantic'])\n",
    "\n",
    "# Create Dataset instances\n",
    "train_dataset = CrushSet(X_train_final, y_train_final)\n",
    "test_dataset = CrushSet(X_test_encoded, y_test)\n",
    "val_dataset = CrushSet(X_val, y_val)\n",
    "\n",
    "# Create DataLoaders\n",
    "BS = 32  # yeah, let's go with the default batch size\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
